# RAG System Configuration

rag:
  chunking:
    strategy: "paragraph"  # Options: paragraph, sentence, fixed
    max_tokens: 512
    overlap_tokens: 50

  retrieval:
    top_k: 5
    similarity_threshold: 0.3  # Lowered from 0.7 for small datasets

  generation:
    max_tokens: 1024
    temperature: 0.7
    system_prompt: |
      You are an AI assistant answering questions about a person's CV/resume.
      Use the provided context to answer accurately and specifically.
      If the information is not in the context, clearly state that you don't have that information.
      Always be professional and concise.

embedding:
  model_name: "all-MiniLM-L6-v2"
  device: "cpu"  # Options: cpu, cuda
  batch_size: 32
  normalize_embeddings: true

vector_store:
  metric: "cosine"  # Options: cosine, euclidean, dotproduct
  dimension: 384  # all-MiniLM-L6-v2 produces 384-dimensional vectors
  namespace: "cv"  # Pinecone namespace for organizing data

conversation:
  max_history_turns: 5
  persist_to_disk: true
  save_path: "data/temp/conversation_history.json"
  session_timeout_minutes: 60

logging:
  version: 1
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
